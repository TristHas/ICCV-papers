\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{antol2015vqa}
\citation{zhang2016yin}
\citation{goyal2017making}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\@writefile{brf}{\backcite{antol2015vqa}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{zhang2016yin}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{goyal2017making}{{1}{1}{section.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Background}{2}{section.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Illustration of a Printed Circuit Board. Copper circuits are made with various insulators for several purposes. }}{2}{figure.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Illustration of a copper roughness surface. (Left) a perfectly smooth surface provides small adhesive surface as the interface between copper, in brown, and the resin, in green is minimal. (Right) a rough surface provides a larger surface at the interface of the resin. Larger contact surface areas provide higher adhesive potency. }}{2}{figure.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Illustration of a few images from the dataset. (Top) Full images. (Down) Zoomed-in areas of $200 \times 200$ pixels. (Right) Sample image of label $t=1$. (Left) Sample image of label $t=10$. The difference between both images are minimal to an untrained eye. Precisely defining the visible difference with words is a difficult task. }}{3}{figure.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Method}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Dataset and Notations}{3}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Baseline}{3}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Illustration of our baseline architecture. With our modular architecture definition, the architecture is fully defined by parameters $n$,$N$,$c$ and $d$. }}{3}{figure.4}}
\citation{yosinski2015understanding}
\citation{you2016image}
\citation{li2018knowing}
\citation{ronneberger2015u}
\citation{lee2017superhuman}
\citation{smith2016deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Assumptions}{4}{subsection.3.3}}
\@writefile{brf}{\backcite{yosinski2015understanding}{{4}{3.3}{subsection.3.3}}}
\@writefile{brf}{\backcite{you2016image}{{4}{3.3}{subsection.3.3}}}
\@writefile{brf}{\backcite{li2018knowing}{{4}{3.3}{subsection.3.3}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  Illustration of binary segmentation masks. White pixels represent areas of high adhesive potency and black surface represent areas of low adhesive potency. We make the assumption that the ratio of white surface is constant for different samples (top and bottom) with equal label $t$. The exact value of this ratio is defined by the target function $f$. }}{4}{figure.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}\hskip -1em.\nobreakspace  {}Architecture}{4}{subsection.3.4}}
\@writefile{brf}{\backcite{ronneberger2015u}{{4}{3.4}{subsection.3.4}}}
\@writefile{brf}{\backcite{lee2017superhuman,smith2016deep}{{4}{3.4}{subsection.3.4}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Illustration of the segmentation model architecture. This architecture follows standard practice in UNet-like segmentation architectures. }}{4}{figure.6}}
\citation{park2016attentive}
\citation{yosinski2015understanding}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}\hskip -1em.\nobreakspace  {}Loss Function}{5}{subsection.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}\hskip -1em.\nobreakspace  {}Target Function}{5}{subsection.3.6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Related Work}{5}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}CNN Interpretability}{5}{subsection.4.1}}
\@writefile{brf}{\backcite{park2016attentive}{{5}{4.1}{subsection.4.1}}}
\citation{carter2019activation}
\citation{xu2015show}
\citation{xu2015show}
\citation{you2016image}
\citation{antol2015vqa}
\citation{zhang2016yin}
\citation{goyal2017making}
\citation{simonyan2014very}
\citation{russakovsky2015imagenet}
\citation{szegedy2013deep}
\citation{sermanet2013overfeat}
\citation{girshick2014rich}
\citation{he2015spatial}
\citation{girshick2015fast}
\citation{ren2015faster}
\citation{bilen2016weakly}
\citation{peyre2017weakly}
\citation{arandjelovic2016netvlad}
\citation{bilen2014weakly}
\citation{bilen2015weakly}
\citation{song2014learning}
\citation{vorontsov2019boosting}
\citation{tang2016large}
\citation{ke2019multi}
\citation{goh2017deep}
\citation{gawehn2016deep}
\citation{chen2018rise}
\citation{webb2018deep}
\citation{pilania2013accelerating}
\citation{hansen2015machine}
\citation{ward2016general}
\citation{liu2017materials}
\citation{lubbers2017inferring}
\citation{li2018automated}
\citation{nash2018review}
\citation{evans2018novo}
\citation{regier2015celeste}
\@writefile{brf}{\backcite{yosinski2015understanding}{{6}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{carter2019activation}{{6}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{xu2015show}{{6}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{xu2015show,you2016image}{{6}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{antol2015vqa,zhang2016yin,goyal2017making}{{6}{4.1}{subsection.4.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Weakly Supervised Segmentation}{6}{subsection.4.2}}
\@writefile{brf}{\backcite{simonyan2014very,russakovsky2015imagenet}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{szegedy2013deep}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{sermanet2013overfeat}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{girshick2014rich}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{he2015spatial}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{girshick2015fast}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{ren2015faster}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{bilen2016weakly}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{peyre2017weakly}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{arandjelovic2016netvlad}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{bilen2014weakly}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{bilen2015weakly}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{song2014learning}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{vorontsov2019boosting}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{tang2016large}{{6}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{ke2019multi}{{6}{4.2}{subsection.4.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.\nobreakspace  {}Machine Learning for Material Science}{6}{subsection.4.3}}
\@writefile{brf}{\backcite{goh2017deep}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{gawehn2016deep}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{chen2018rise}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{webb2018deep}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{pilania2013accelerating}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{hansen2015machine}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{ward2016general}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{liu2017materials}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{lubbers2017inferring}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{li2018automated}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{nash2018review}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{evans2018novo}{{6}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{regier2015celeste}{{6}{4.3}{subsection.4.3}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Experiments}{6}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}\hskip -1em.\nobreakspace  {}Classification results}{6}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  Results of the human evaluation. (Left) Regression plot on the test set. The blue line illustrates the ground-truth labels. Each yellow dot represents the expert's predicted labels on individual images. The yellow line represents the expert's average answers for images of similar ground-truth label. (Right) Expert's answers visualized as a confusion matrix. }}{6}{figure.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  Results of the model evaluation. (Left) Regression plot. Blue dots represent predictions on the training samples, yellow dots represent validation samples and green dots represent the test samples. (Right) Confusion matrix of the test samples }}{7}{figure.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}\hskip -1em.\nobreakspace  {}Visualization of Segmentation Results}{7}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}\hskip -1em.\nobreakspace  {}Investigation of the hypothesis function}{7}{subsection.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  Visualization of the segmentation model output. (Left): Zoomed-in input image. (Right): Model segmentation output overlaid on the input image. Blue areas represent 1 values (high adhesive potency) and red areas represent 0 values (low adhesive potency). }}{7}{figure.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces  Results of the segmentation model evaluation. The red line illustrates the linear hypothesis used for training. Blue, yellow and green dots represent individual image output predictions on the training, validation and test set respectively. Even on training samples, the model is not able to overfit the ground labels generated by the hypothesis function. Instead of a linear decay, the model seems to predict a more aggressive decay, following a square root or logarithmic trend. }}{7}{figure.10}}
\bibstyle{ieee}
\bibdata{egbib}
\bibcite{antol2015vqa}{1}
\bibcite{arandjelovic2016netvlad}{2}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces  Results of the segmentation model evaluation with different hypothesis function $g$. (Left) $g=1-t^{-\frac  {1}{2}}$. The model seems to nicely fit the hypothesis function. (Middle) $g=1-t^{-2}$. The model diverges from the hypothesis function, suggesting a more rapid decay. (Right) $g=sign(-1^{t})$. The model struggles to learn the hypothesis function, yielding high errors. }}{8}{figure.11}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Discussion \& Conclusion}{8}{section.6}}
\bibcite{bilen2014weakly}{3}
\bibcite{bilen2015weakly}{4}
\bibcite{bilen2016weakly}{5}
\bibcite{carter2019activation}{6}
\bibcite{chen2018rise}{7}
\bibcite{evans2018novo}{8}
\bibcite{gawehn2016deep}{9}
\bibcite{girshick2015fast}{10}
\bibcite{girshick2014rich}{11}
\bibcite{goh2017deep}{12}
\bibcite{goyal2017making}{13}
\bibcite{hansen2015machine}{14}
\bibcite{he2015spatial}{15}
\bibcite{ke2019multi}{16}
\bibcite{lee2017superhuman}{17}
\bibcite{li2018automated}{18}
\bibcite{li2018knowing}{19}
\bibcite{liu2017materials}{20}
\bibcite{lubbers2017inferring}{21}
\bibcite{nash2018review}{22}
\bibcite{park2016attentive}{23}
\bibcite{peyre2017weakly}{24}
\bibcite{pilania2013accelerating}{25}
\bibcite{regier2015celeste}{26}
\bibcite{ren2015faster}{27}
\bibcite{ronneberger2015u}{28}
\bibcite{russakovsky2015imagenet}{29}
\bibcite{sermanet2013overfeat}{30}
\bibcite{simonyan2014very}{31}
\bibcite{smith2016deep}{32}
\bibcite{song2014learning}{33}
\bibcite{szegedy2013deep}{34}
\bibcite{tang2016large}{35}
\bibcite{vorontsov2019boosting}{36}
\bibcite{ward2016general}{37}
\bibcite{webb2018deep}{38}
\bibcite{xu2015show}{39}
\bibcite{yosinski2015understanding}{40}
\bibcite{you2016image}{41}
\bibcite{zhang2016yin}{42}
