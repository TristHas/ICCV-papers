\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{Assisting human experts in the interpretation of their visual process: A case study on assessing copper sheet surface adhesive potency}%

\author{
Tristan Hascoet\\
Kobe University\\
{\tt\small tristan@people.kobe-u.ac.jp}
\and
To-san\\
Kobe University\\
{\tt\small xxx}
\and
Sachiko Nakamura\\
xxx\\
xxx\\
{\tt\small xxx}
\and
Tomoko Hayashi\\
xxx\\
xxx\\
{\tt\small xxx}
\and
Mari Sugiyama\\
xxx\\
xxx\\
{\tt\small xxx}
\and
Yasuo Ariki\\
xxx\\
xxx\\
{\tt\small xxx}
\and
Tetusya Takiguchi\\
xxx\\
xxx\\
{\tt\small xxx}
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
Deep Neural Networks are often though to lack interpretability due to the distributed nature of their internal representations. In contrast, humans can generally justify, in natural language, for their answer to a visual question with simple common sense reasoning. However, human introspection abilities have their own limits as one often struggles to justify for the recognition process behind our lowest level feature recognition ability: for instance, it is difficult to precisely explain why a given texture seems more characteristic of the surface of a finger nail rather than plastic bottle.
In this paper, we showcase an application in which deep learning models can actually  help human experts justify for their own low-level visual recognition process: We study the problem of assessing the adhesive potency of copper sheets from microscopic pictures of their surface . Although highly trained material experts are able to qualitatively assess the surface adhesive potency, they are often unable to precisely justify for their decision process. We present a model that, under careful design considerations, is able to provide visual clues for human experts to understand and justify for their own recognition process. 
Not only can our model assist human experts in their interpretation of the surface characteristics, 
we show how this model can be used to test different hypothesis of the copper surface response to different manufacturing processes. 
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

% Human explanation ability & deep learning flaws.
Humans are experts in communicating the reasoning process behind their answer to visual questions.
For instance, on typical Visual Question Answering (VQA) samples, 
human annotators are often able to precisely justify in natural language the reason 
behind their answer to a certain visual question using simple common sense reasoning.
%Common sense includes spatial and causal relationships
In contrast, deep Learning models are often viewed as black box predictors lacking interpretability 
in the sense that existing tools often fail to explain the decision making process behind the model’s predictions.
For instance, a deep learning model trained end-to-end on a VQA dataset may be able to provide the same answer as its
human counterpart, but xxx.

% Limits of low-level introspection
While it is true that humans can justify for their answers on high level reasoning tasks, 
humans also often fail to explain the process behind their low-level feature recognition ability:
for example, precisely defining the nature of a specific texture (what are the defining features of a plastic or wooden surface?) or specific low-level part attributes exhibiting large intra-class variations (what is the defining features of a "leg" or a "wing"?).
Humans constantly perform such low-level visual recognition tasks while being unable to precisely justify for their own recognition process.

% Current problem
In this paper, we present one very practical instance of such situation in the micro-processor chip industry, 
in which expert material scientists are tasked with assessing the adhesive potency of copper sheets.
We propose a model that, under careful design considerations, is able to provide visual clues 
for human experts to understand and justify for their decision process.

% Ability of our proposed model.
The proposed model is designed so that a subset of its internal representations carry semantically meaningful 
Information that can be visualized and easily interpreted by humans.
Providing these visual clues, however, comes with the cost of imposing additional constraints on the architecture,
which we found to degrade the model accuracy:
Indeed, we found that networks with unrestricted architectures, 
(which do not provide interpretable features)
perform better than network architectures restricted so as to provide 
semantically meaningful representations.
This is because, as we restrict the architecture of the model, 
we formulate an assumption on the impact of the manufacturing process 
on the surface statistics which may not hold in reality.
This result suggest an inherent trade-off between the 
expressivity of an architecture and the explainability of its process.

%the human experts, confirming their intuitions 
%and eventually shading light on their own decision processes and biases
% Test hypothesis using generalization performance as a metric of hypothesis validity
While the degradation of the model accuracy is problematic from a performance perspective,
it offers an interesting opportunity from an explainability perspective:
As the model accuracy degrades due to the inadequacy of the assumption implicitly formulated by the model architecture,
we can use the model accuracy as a proxy metric for the adequacy of different assumptions.
This allows us to quantitavely assess different assumptions regarding the impact 
of manufacturing processes on the copper surface. 
This may prove useful to quantify the impact of manufacturing process on cooper surface adhesive potency
and eventually help optimize the manufacturing process.

% Learn a hypothesis/theoretical model
%Going one step further we show how, given sufficient experimental data, the model
%can be augmented to automatically learn and formulate these hypothesis on itself.
% Conceptual contribution
In essence, the argument this paper is aiming for is as follows: although deep learning models 
lack the "common sense reasoning” abilities and the powerful formalism of natural language to communicate 
and justify for their decision making process, they can provide powerful to explain low-level recognition processes.

% Practical contribution
In practice, the contribution of this paper is as follows:
\begin{enumerate}
\item  We formalize a segmentation procedure based on a probabilistic weak label segmentation framework.
\item  We introduce a formalism to show how the model accuracy can be used as a proxy metric to quantify the validity of different assumptions
on the dataset.
\end{enumerate}

% Paper organization
The remainder of this paper is organized as follows:
In Section 2, we present some background information on the motivation for this project:
We start by discussing the importance of copper surface adhesive potency,
and detail the dataset used in our experiments. 
Section 3 details our contribution.
Section 4 briefly relates our work to different research topics and Section 5 presents the results of our experiments.
Finally, Section 6 further discusses the relevance of our results, insisting on the limitations of our assumptions to conclude this paper.

%------------------------------------------------------------------------
\section{Background}

%% Catchy intro about the importance of chips
Electric circuits are core to a wide variety of electronic devices including industrial and household appliances (e.g. fridges and microwaves), mobile communication devices and automobiles.
%% Glue copper and resin together
To propagate electric signals between various components, electronic circuits rely on an electronic substrate  made of copper wires through which electricity flows, isolated from each other by insulators (resin, resist, prepreg, etc.).
Electronic substrates are organized in a multi-layered structure in which each layer contains different wire connections that need to be properly isolated from each other. Figure 1 illustrates the organization of such an electric circuit.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\linewidth]{"./figures/Figure1"}
\caption{
Illustration of a typical eletric circuit board.
}
\end{figure}


% Problem of peelin off
The bulit-in copper microstructures can be easily peeled off from their isolating resin due to weak adhesion. For example, this can happen because of the impact of dropping a smartphone, or due to an excess of heat generated by running heavy computations.
Such disadhesion of copper wires with their isolating resin may result in electrical short circuits in the electronic substrate and break the device.
Hence a strong metal-to-resin bonding is necessary in order to enhance the reliability of electronic devices.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{"./figures/Figure2"}
	\caption{
		Illustration of xxx
	}
\end{figure}

% Copper surface importance
Among other factors, the achievable strenght of the bond between the copper and the isolating resin is determined by the characteristics of the copper surface, as illustrated in Figure 2. In very broad terms, rough surfaces allow for stronger bonds as the asperities of the surface provide mechanical support against friction forces. In contrast, smooth surfaces provide little support against friction so that they have lower adhesive potential. 
In the remaining of this paper, we will refer to the potential bonding strength of a copper surface as its "adhesive potency".
It is also important to note that the adhesive potency of a copper surface is related to its "roughness", which is observable at the microscopic scale.

% Difficulty of assessment
Electronic substrate manufacturers have developped advanced manufacturing processes to shape the surface of copper sheets in order to increase their adhesive potency. This is typically achieved by applying a very small amount of a corrosive solution on the copper surface.
Being able to accurately assess the adhesive potency of a copper surface would allow to further optimize manufacturing processes to increase the reliability of electronic devices.
However, assessing the adhesive potency of a copper surface is a complex task, even for the most expert practinioners. 
Hence the motivations of this study is two fold: 
First we aim to automate the evaluation of a copper sheet adhesive potency from microscopic imaging of its surface. 
Second, we aim to understand the underlying principles by which the xxx 
Towards this goal, we built a dataset of microscopic images of copper surfaces, which we detail below.

%% Dataset
We imaged copper surfaces using Scanning Electron Microscopy (SEM) at a resolution of $xxx$ micro meters.
To investigate the impact of different manufacturing processes on the copper surface, 
we applied 16 different corosive solutions, with decreasing corrosive power, to the copper surface.
For each of these solutions, we captured 50 SEM images of $xxx \times xxx$ pixels so that the full dataset
consists of $800$ ($16 \times 50$) images.
%The corrosive power of each solution was degraded by a constant factor $\delta$ between each 
Each image is annotated with a label $y_i \in Y$ corresponding to the corrosive solution used to shape the copper surface.
Each solution $y_i$ was obtained by submitting the original solution $y_0$ to an extreme stress test for a period of time $i \times T$.
Hence, we know that for all $i$ images of copper surfaces with label $y_i$ show higher adhesive potency than the images labelled with $y_{i+1}$.
However, we do not know the \textit{exact} impact of the stress test on the surface adhesive potency.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{"./figures/Figure2"}
	\caption{
		Illustration of xxx
	}
\end{figure}

\section{Method}

\subsection{Dataset and Notations}


In all our following experiments, we have split the full dataset $\mathcal{D}$ into a training, validation and test set $\mathcal{D}=\mathcal{D}_{tr} \cup \mathcal{D}_{val} \cup \mathcal{D}_{te}$ so that the number of images per label $y_i$ in each set is 40, 5 and 5 respectively.

\subsection{Baseline}

We start by establishing a strong baseline for our study.
The baseline architecture follows standard convolutional network designs for image classification.
This architecture, illustrated in Figure 4, is made of several residual blocks 
sequentially interleaved with max pooling operations.
Each residual block consists of $n$ repetitions of a sequence of 
$3 \times 3$ Convolution, Batch Normalization and ReLU layers,
followed by a residual skip connection.
We set $N$ residual blocks between every max pooling layer
and we denote by $d$ the number of pooling layers.
Hence, the full depth $D$ of the network (in number of convolution layers) 
is given by $D=d \times n \times N +1$, where the term $1$ corresponds to the
initial $3 \times 3$ Convolution layer happening before the first pooling operation.
Finally, the top layer of the network is made of a global average pooling layer 
followed by a linear softmax layer with output dimension 15 corresponding to our number of classes.
For simplicity and contrary to standard practices, we keep the number of channels $c$ constant 
in all layers of the network.

With this parameterization, our network is fully specified by the four hyper parameters $c$, $d$, $n$ and $N$.
We then perform a grid search over these hyper parameters to identify the best performing architecture.
The details of this architecture search are given in the experiment section.
As we shall see then, the best performing architecture performs significantly better than human experts.
However, the decision process through which this model reach such a high accuracy is entirely unclear,
as the distributed nature of the model's internal representations leaves little space for interpretability.
The remainder of this section details our attempt to bring interpretability to the network's processing.

\subsection{Assumptions}
% xxx


\subsection{Architecture restriction}




\subsection{Evaluating Different Hyptohesis}
% xxx





\section{Related Work}
Although deep neural networks have achieved a great success on a variety of challenging visualization tasks in recent years, our understanding of how these neural network models is far from enough to interpret.
The pursuit of figuring out what is learned for each layer of models and how trained neural network models really "think" never stops.

%% Efforts to understand hidden representations
% Visualization works.
 % Jason Yosinski et al.,2015,understanding neural network through deep visualization
Jason Yosinski et al. provide two useful tools for visualizing and interpreting neural nets. One is to visualize  the activations produced on each layer of a trained convnet as it processes an image or video, and the other enables visualizing features at each layer of a DNN via regularized optimization in image space.
 % activation atlas https://distill.pub/2019/activation-atlas/
 %%(Shan Carter et al.2019)
Shan Carter et al. create an explorable activation atlas of features the network has learned, by using feature inversion to visualize millions of activations from an image classification network, which can reveal how the network typically represents some concepts.
 % attention models for image captioning and visual question answering
   %Yashi Goyal et al., CVPR 2017, Marking the V in VQA Matter:Elevating the Role of Image Understanding in Visual Question Answering
   %Peng Zhang et al., CVPR 2016, Yin and Yang:Balancing and Answering Binary Visual Questions
   %Aishwarya Agrawal et al., ICCV 2015, VQA:Visual Question Answering
There is a new dataset called Visual Question Answering(VQA) containing open-ended questions about images.These questions require an understanding of vision, language and commonsense knowledge to answer.
 % Trevor darrel train models to explain their decision 
  %Attentive Explanations: Justifying Decisions and Pointing to the Evidence, Dong Huk Park, 2017
Trevor Darrel et al. build  models (such as Pointing and Justification-based explanation model) to explain their decisions, generating convincing explanations.
TensorFlow provides an attention-based model, which enables us to see what parts of the image the model focuses on as it generates a caption.
%% Deep learning for scientific discovery

Deep learning has showed remarkable success on many important learning problems in chemistry, drug discovery, biology and materials science.

 % Material sciences
   % Discover new materials or properties (messaging passing deep networks by gilmer)
   %%Justin Gilmer,2017, Neural Message Passing for Quantum Chemistry
A general framework for supervised learning on graphs called Message Passing Neural Networks (MPNNs) is widely used on neural computation for predicting quantum states of molecules.
   % Drug discovery: Find molecules useful by predicting their property
   %%Dibyendu Dana et al.,2018, Deep Learning in Drug Discovery and Medicine;Scratching the Surface
   %%Jessica Vamathevan et al.,2019, Applications of machine learning in drug discovery and development
Drug discovery is also benifiting from the development of artificial intelligence technology, which is automating the invention of new chemical entities and the mining of large databases, in drug design and molecular medicine field.  
   % Protein folding
Deep learning approaches such as DeepMind's AlphaFold are helpful for scientists to deal with the "protein folding problem", not only predicting the intricate 3D structure of a protein but also predicting the physical properties of a protein structure, and are making significant progress on one of the core challenges in biology.
   % THIS ONE New Materials for batteries
   %% 
In the field of materials science, deep neural networks have also been receiving inreasing attention and have achieved great improvements, for example, in material property prediction and new materials discovery for batteries.

%% Segmentation from lazy labels.
An other point we should pay attention to is different labelling strategies in conventional supervised learning.
Typically speaking, it's often assumed that each instance is associated with one single label. However, there should usually be more than one labels for one instance in real-world tasks, if it is multi-label learning.

% Detection with weak labels
%%Matthew B.Blaschko et al., 2010,Simultaneous Object Detection and Ranking with Weak Supervision

   %%Ross B. Girshick et al., 2011,Object Detection with Grammar Models
   %%Bharath Hariharan et al.,2014,Simultaneous Detection and Segmentation
   %%Hakan Bilen et al.,2016,Weakly Supervised Deep Detection Networks

  % segmentation weak label https://arxiv.org/pdf/1904.01636.pdf
   %%Eugene Vorontsov et al., 2019, Boosting segmentation with weak supervision from image-to-image translation
Eugene et al. propose a semi-supervised framework that employs image-to-image translation between weak labels.
  % Semi-supervised learning for object detection or semantic segmentation
   %%Yuxing Tang et al.,2016, Large Scale Semi-supervised Object Detection using Visual and Semantic Knowledge Transfer
Yuxing Tang et al. build a similarity-based knowledge transfer mode trying to investigate whether knowledge about visual and semantic similarities of object categories can help improve the peformance of detectors trained in a weakly supervised setting.

% Our work = Merge segmentation from lazy labels and scientific discovery
  %% Rihuan Ke et al., 2019, A multi-task U-net for segmentation with lazy labels
The most related work with ours is Rihuan Ke's[*] in which they present a semi-supervised learning strategy for segmentation with lazy labels and develop a multi-task learning framework to integrate the instance detection, separation and segmentation within a deep neural network.

Our work aim to merge segmentation with lazy labels into scientific discovery and provide material experts with strong supports for interpretable decision.

\section{Experiments}
% xxx
xxx

\subsection{Recognition results}
% xxx
xxx

\subsection{Hypothesis testing}
% xxx
xxx

\subsection{Hypothesis learning}
% xxx
xxx

\section{Conclusion}
% xxx
xxx

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
